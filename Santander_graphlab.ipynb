{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "\n",
    "#needed for charts\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ellfae/Dropbox/MyResearch/kaggle/Santander customer satisfaction/train.csv/train.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ellfae/Dropbox/MyResearch/kaggle/Santander customer satisfaction/train.csv/train.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 3.20835 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 3.20835 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[int,int,int,int,float,float,float,float,int,int,float,float,float,int,int,float,int,int,float,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,float,float,int,float,float,int,int,int,int,int,float,int,float,float,float,float,int,int,int,float,float,int,int,int,float,float,int,float,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,float,float,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,float,float,float,float,float,float,float,float,float,int,float,float,float,float,int,float,int,int,int,int,int,int,int,int,float,int,float,float,int,int,int,int,int,int,int,int,int,int,int,int,float,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 67150 lines. Lines per second: 11724.5</pre>"
      ],
      "text/plain": [
       "Read 67150 lines. Lines per second: 11724.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ellfae/Dropbox/MyResearch/kaggle/Santander customer satisfaction/train.csv/train.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ellfae/Dropbox/MyResearch/kaggle/Santander customer satisfaction/train.csv/train.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 76020 lines in 7.05582 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 76020 lines in 7.05582 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ellfae/Dropbox/MyResearch/kaggle/Santander customer satisfaction/test.csv/test.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ellfae/Dropbox/MyResearch/kaggle/Santander customer satisfaction/test.csv/test.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 2.2635 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 2.2635 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[int,int,int,int,float,float,int,int,int,int,int,float,float,float,float,float,float,float,float,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,float,int,float,float,float,int,int,float,int,int,int,int,float,float,float,int,int,int,float,float,float,float,int,float,int,int,float,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,float,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,float,float,float,float,int,float,float,float,float,float,float,float,float,float,float,float,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,float,int,int,float,int,int,int,int,float]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 67325 lines. Lines per second: 16200.2</pre>"
      ],
      "text/plain": [
       "Read 67325 lines. Lines per second: 16200.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ellfae/Dropbox/MyResearch/kaggle/Santander customer satisfaction/test.csv/test.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ellfae/Dropbox/MyResearch/kaggle/Santander customer satisfaction/test.csv/test.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 75818 lines in 4.48316 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 75818 lines in 4.48316 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the train and test data\n",
    "customers = gl.SFrame('train.csv/train.csv')\n",
    "test_sframe = gl.SFrame('test.csv/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gl.canvas.set_target('ipynb')\n",
    "#customers['TARGET'].show(view='Categorical')\n",
    "#customers.head().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\n"
     ]
    }
   ],
   "source": [
    "print customers.num_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove all columns with constant columns; where STD == 0\n",
    "remove = []\n",
    "\n",
    "for col in customers.column_names():\n",
    "    if customers[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "customers.remove_columns(remove)\n",
    "customers.num_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_var2_0', 'ind_var2', 'ind_var27_0', 'ind_var28_0', 'ind_var28', 'ind_var27', 'ind_var41', 'ind_var46_0', 'ind_var46', 'num_var27_0', 'num_var28_0', 'num_var28', 'num_var27', 'num_var41', 'num_var46_0', 'num_var46', 'saldo_var28', 'saldo_var27', 'saldo_var41', 'saldo_var46', 'imp_amort_var18_hace3', 'imp_amort_var34_hace3', 'imp_reemb_var13_hace3', 'imp_reemb_var33_hace3', 'imp_trasp_var17_out_hace3', 'imp_trasp_var33_out_hace3', 'num_var2_0_ult1', 'num_var2_ult1', 'num_reemb_var13_hace3', 'num_reemb_var33_hace3', 'num_trasp_var17_out_hace3', 'num_trasp_var33_out_hace3', 'saldo_var2_ult1', 'saldo_medio_var13_medio_hace3']\n"
     ]
    }
   ],
   "source": [
    "print remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicated columns (too slow!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "#computed on kaggle\n",
    "remove_duplicated = ['ind_var29_0', 'ind_var29', 'ind_var13_medio', 'ind_var18', 'ind_var26', \n",
    "                     'ind_var25', 'ind_var32', 'ind_var34', 'ind_var37', 'ind_var39', 'num_var29_0', \n",
    "                     'num_var29', 'num_var13_medio', 'num_var18', 'num_var26', 'num_var25', 'num_var32', \n",
    "                     'num_var34', 'num_var37', 'num_var39', 'saldo_var29', 'saldo_medio_var13_medio_ult1', \n",
    "                     'delta_num_reemb_var13_1y3', 'delta_num_reemb_var17_1y3', 'delta_num_reemb_var33_1y3', \n",
    "                     'delta_num_trasp_var17_in_1y3', 'delta_num_trasp_var17_out_1y3', \n",
    "                     'delta_num_trasp_var33_in_1y3', 'delta_num_trasp_var33_out_1y3']\n",
    "\n",
    "customers.remove_columns(remove_duplicated)\n",
    "print customers.num_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sum of 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select on the features, leaving out the 'TARGET' feature\n",
    "features = [f for f in customers.column_names() if f != 'TARGET']\n",
    "\n",
    "## NOTE: Causes overfitting (need to study why)\n",
    "# add the sum of 0's\n",
    "customers['sum_of_0'] = customers[features].apply(lambda x: len([i for i in x.values() if i != 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch missing value on var3 (assumption that it is nationality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# at first only age = -999999 was considered but then we also replaced 0 with 2 and this also helped to improve result\n",
    "def fix_age(nat):\n",
    "    if nat == -999999 and nat == 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return nat\n",
    "\n",
    "customers['var3'] = customers['var3'].apply(fix_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add binary line based on var38 mean (assumption that it is mortgage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(customers[customers['var3']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove low variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# it did improve the results a little -> 0.811884 -> 0.812585\n",
    "# These features were spitted with low variance from the classifier\n",
    "low_variance_features = ['delta_imp_reemb_var33_1y3',  'imp_reemb_var17_hace3', 'imp_reemb_var33_ult1', 'imp_trasp_var17_in_hace3', 'num_reemb_var17_hace3', 'num_reemb_var33_ult1', 'num_trasp_var17_in_hace3']\n",
    "customers.remove_columns(low_variance_features)\n",
    "customers.num_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#customers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Target are 0, which means most customers are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = customers.random_split(.8, seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Boosted Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "customer_model = gl.boosted_trees_classifier.create(train_data, target='TARGET', row_subsample=0.7, \n",
    "                                                    max_depth=5, metric='auc',\n",
    "                                                   column_subsample=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Deep Learning Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "customer_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = customer_model.predict(test_sframe, output_type='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function for making submission\n",
    "def make_submission(prediction, filename='submission.txt'):\n",
    "    with open(filename, 'w') as f:\n",
    "        #header\n",
    "        f.write('ID,TARGET\\n')\n",
    "        submission_strings = test_sframe['ID'].astype(str) + ',' + prediction.astype(str)\n",
    "        for row in submission_strings:\n",
    "            f.write(row + '\\n')\n",
    "\n",
    "make_submission(prediction, 'submission13.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# removing columns that are giving the same information\n",
    "import numpy as np\n",
    "remove_duplicates = []\n",
    "c = customers.column_names()\n",
    "#test = customers['TARGET'].to_numpy()\n",
    "for i in range(len(c) - 1):\n",
    "    v = customers[c[i]].to_numpy()\n",
    "    for j in range(i+1, len(c)):\n",
    "        if np.array_equal(v, customers[c[j]].to_numpy()):\n",
    "            remove_duplicates.append(c[j])\n",
    "    print \"round\", i, \"done\"\n",
    "print remove_duplicates\n",
    "#giving the same information ???\n",
    "\n",
    "\n",
    "######################################################################3\n",
    "\n",
    "def mortgage_divide(mortgage):\n",
    "    if mortgage < 100000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "customers['mortgage_divider'] = customers['var38'].apply(mortgage_divide)\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "#net = gl.deeplearning.create(train_data, target='TARGET')\n",
    "net = gl.deeplearning.MultiLayerPerceptrons(num_hidden_layers=4,\n",
    "                                           num_hidden_units=[32,64,32,2],\n",
    "                                           activation='relu',\n",
    "                                           learning_rate=0.001,\n",
    "                                           max_iterations=5000)\n",
    "                                           \n",
    "dl_customer_model = gl.neuralnet_classifier.create(train_data,'TARGET',\n",
    "                                                  network=net,\n",
    "                                                  valiation_data=test_data)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

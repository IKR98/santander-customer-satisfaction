{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with  1\n",
      "Done with  2\n",
      "Done with  3\n",
      "Done with  4\n",
      "Done with  5\n",
      "Done with  6\n",
      "Done with  7\n",
      "Done with  8\n",
      "Done with  9\n",
      "Done with  10\n",
      "Done with  11\n",
      "Done with  12\n",
      "Done with  13\n",
      "Done with  14\n",
      "Done with  15\n",
      "Done with  16\n",
      "Done with  17\n",
      "Done with  18\n",
      "Done with  19\n",
      "Done with  20\n",
      "Iteration 1, loss = 0.16483979\n",
      "Validation score: 0.962028\n",
      "Iteration 2, loss = 0.14593314\n",
      "Validation score: 0.962115\n",
      "Iteration 3, loss = 0.14265333\n",
      "Validation score: 0.962203\n",
      "Iteration 4, loss = 0.14100422\n",
      "Validation score: 0.962028\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Overall AUC: 0.826939093042\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "df_train = pd.read_csv('train.csv//train.csv')\n",
    "df_test = pd.read_csv('test.csv/test.csv')\n",
    "\n",
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "y_train = df_train['TARGET'].values\n",
    "X_train = df_train.drop(['ID','TARGET'], axis=1).values\n",
    "\n",
    "id_test = df_test['ID']\n",
    "X_test = df_test.drop(['ID'], axis=1).values\n",
    "\n",
    "len_train = len(X_train)\n",
    "len_test  = len(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(128,64,128), \n",
    "\t\t\t\t\tactivation='relu', \n",
    "     \t\t\t\tbeta_1=0.9, \n",
    "     \t\t\t\tbeta_2=0.9,\n",
    "                    alpha = 0.001,\n",
    "                    early_stopping = True,\n",
    "                    shuffle = True,\n",
    "                    warm_start = True,\n",
    "                    validation_fraction = 0.3,\n",
    "     \t\t\t\tlearning_rate_init=0.001, \n",
    "     \t\t\t\tmax_iter = 14000, \n",
    "     \t\t\t\trandom_state = 1235, \n",
    "     \t\t\t\tlearning_rate='adaptive',\n",
    "                    verbose=True)\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred= clf.predict_proba(X_test)[:,1]\n",
    "print('Overall AUC:', roc_auc_score(y_train, clf.predict_proba(X_train)[:,1]))\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_pred})\n",
    "submission.to_csv(\"submission200.csv\", index=False)\n",
    "\n",
    "print('Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
